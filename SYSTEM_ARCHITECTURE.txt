================================================================================
                    ARCHITECH - SYSTEM ARCHITECTURE
================================================================================

PROJECT: ARCHITECH - Architectural Recovery & Semantic Synthesis Platform
DOCUMENT: Complete System Architecture
VERSION: 1.0
DATE: 2024

================================================================================
                        TABLE OF CONTENTS
================================================================================

1. ARCHITECTURE OVERVIEW
2. TECHNOLOGY STACK
3. COMPONENT ARCHITECTURE
4. DATA FLOW
5. API ARCHITECTURE
6. DEPLOYMENT ARCHITECTURE
7. PERFORMANCE CHARACTERISTICS

================================================================================
                    1. ARCHITECTURE OVERVIEW
================================================================================

ARCHITECH follows a 3-TIER ARCHITECTURE:

Tier 1: FRONTEND (React SPA)
  - Port: 3000
  - Technology: React 18.2.0
  - Purpose: User interface and visualization

Tier 2: BACKEND (FastAPI Server)
  - Port: 8000
  - Technology: Python FastAPI
  - Purpose: Analysis engine and API

Tier 3: DATABASES (Neo4j + ChromaDB)
  - Neo4j Port: 7687 (Bolt), 7474 (HTTP)
  - ChromaDB: Local file system
  - Purpose: Data persistence

COMMUNICATION:
  Frontend <--HTTP/REST--> Backend <--Bolt/File--> Databases

ARCHITECTURE PATTERN: Monolithic Backend + SPA Frontend

================================================================================
                        2. TECHNOLOGY STACK
================================================================================

--------------------------------------------------------------------------------
2.1 FRONTEND STACK
--------------------------------------------------------------------------------

Core Framework:
  - React 18.2.0 (UI library)
  - React Scripts 5.0.1 (Build tools)

HTTP Client:
  - Axios 1.6.0 (API communication)

Visualization:
  - D3.js 7.8.5 (Graph rendering)

State Management:
  - React Hooks (useState, useEffect)

Styling:
  - CSS3 (Custom styles)

Build Tools:
  - Webpack (via React Scripts)
  - Babel (Transpilation)

--------------------------------------------------------------------------------
2.2 BACKEND STACK
--------------------------------------------------------------------------------

Web Framework:
  - FastAPI 0.115.0 (REST API)
  - Uvicorn 0.32.0 (ASGI server)

Code Parsing:
  - Tree-sitter 0.23.0 (AST parser)
  - tree-sitter-python 0.23.0
  - tree-sitter-javascript 0.23.0

Graph Database:
  - Neo4j 5.14.1 (Python driver)

Vector Database:
  - ChromaDB 0.5.23 (Embeddings)
  - sentence-transformers 3.0.0 (Embedding model)

Graph Analysis:
  - NetworkX 3.2.1 (Graph algorithms)

LLM Integration:
  - Groq 0.11.0 (LLM API client)

Repository Management:
  - GitPython 3.1.40 (Git operations)

Utilities:
  - Pydantic 2.9.0 (Data validation)
  - python-dotenv 1.0.0 (Environment variables)
  - httpx 0.27.0 (HTTP client)

--------------------------------------------------------------------------------
2.3 DATABASE STACK
--------------------------------------------------------------------------------

Graph Database:
  - Neo4j 5.14 Community Edition
  - Deployment: Docker container
  - Storage: Persistent volume

Vector Database:
  - ChromaDB (Embedded)
  - Storage: Local file system (chroma_db/)
  - Embedding Model: all-MiniLM-L6-v2 (384 dimensions)

--------------------------------------------------------------------------------
2.4 INFRASTRUCTURE
--------------------------------------------------------------------------------

Version Control:
  - Git

Containerization:
  - Docker (Neo4j only)

Runtime:
  - Python 3.9+
  - Node.js 16+

Operating System:
  - Windows (Development)
  - Linux (Production-ready)

================================================================================
                    3. COMPONENT ARCHITECTURE
================================================================================

--------------------------------------------------------------------------------
3.1 FRONTEND COMPONENTS
--------------------------------------------------------------------------------

App.js (Main Container)
  |
  +-- AnalyzeRepo (Repository input and analysis trigger)
  |
  +-- PatternDetection (Architectural pattern display)
  |
  +-- CouplingAnalysis (Coupling metrics display)
  |
  +-- ImpactAnalysis (Change impact prediction)
  |
  +-- ArchitectureView (Multi-level explanations)
  |
  +-- DependencyGraph (D3.js visualization)

Services:
  - api.js (Axios HTTP client)
    - analyzeRepo()
    - getPatterns()
    - getCoupling()
    - analyzeImpact()
    - getArchitecture()
    - getBlastRadius()
    - getDependencies()

--------------------------------------------------------------------------------
3.2 BACKEND COMPONENTS
--------------------------------------------------------------------------------

main.py (FastAPI Application)
  |
  +-- API Routes
  |   - POST /analyze
  |   - GET /status/{job_id}
  |   - GET /patterns
  |   - GET /coupling
  |   - POST /impact
  |   - GET /architecture
  |   - GET /blast-radius/{path}
  |   - GET /dependencies/{path}
  |   - GET /graph/data
  |   - GET /graph/functions
  |
  +-- Analysis Engine (analysis_engine.py)
      |
      +-- Parser Module
      |   - repo_loader.py (Repository cloning)
      |   - static_parser.py (AST parsing)
      |
      +-- Graph Module
      |   - graph_db.py (Neo4j operations)
      |   - dependency_mapper.py (Dependency analysis)
      |   - analyzers.py (Pattern detection, coupling)
      |   - blast_radius.py (Impact analysis)
      |   - function_graph.py (Function call graphs)
      |   - version_tracker.py (Snapshot management)
      |
      +-- Retrieval Module
      |   - vector_store.py (ChromaDB operations)
      |   - retrieval_engine.py (Hybrid retrieval)
      |
      +-- Reasoning Module
          - llm_reasoner.py (LLM integration)

--------------------------------------------------------------------------------
3.3 DATABASE COMPONENTS
--------------------------------------------------------------------------------

Neo4j Graph Database
  |
  +-- Nodes
  |   - File (source files)
  |   - Class (class definitions)
  |   - Function (function definitions)
  |   - Module (imported modules)
  |   - Repository (analyzed repos)
  |   - Snapshot (analysis snapshots)
  |
  +-- Relationships
      - CONTAINS (File -> Class/Function)
      - IMPORTS (File -> Module/File)
      - CALLS (Function -> Function)
      - INHERITS (Class -> Class)
      - DEPENDS_ON (File -> File)
      - HAS_SNAPSHOT (Repository -> Snapshot)
      - BELONGS_TO (Entity -> Snapshot)

ChromaDB Vector Database
  |
  +-- Collection: code_embeddings
      - Documents: Code snippets
      - Embeddings: 384-dimensional vectors
      - Metadata: File path, type, language, repo_id

================================================================================
                        4. DATA FLOW
================================================================================

--------------------------------------------------------------------------------
4.1 REPOSITORY ANALYSIS FLOW
--------------------------------------------------------------------------------

Step 1: User Input
  User enters GitHub URL in frontend
  Frontend: AnalyzeRepo component

Step 2: API Request
  POST /analyze {repo_url: "https://github.com/..."}
  Backend: main.py receives request

Step 3: Background Job Creation
  job_id = uuid.uuid4()
  jobs[job_id] = {"status": "processing"}
  background_tasks.add_task(run_analysis, job_id, repo_url)
  Return: {"job_id": "...", "status": "processing"}

Step 4: Repository Cloning
  RepositoryLoader.clone_repo(repo_url)
  Output: Local path to cloned repository

Step 5: File Scanning
  Scan directory for source files (.py, .js, .java)
  Filter out non-source files
  Output: List of file paths

Step 6: AST Parsing
  For each file:
    StaticParser.parse_file(file_path)
    Extract: classes, functions, imports
  Output: Parsed data structure

Step 7: Graph Storage
  For each parsed file:
    GraphDB.store_file(file_data)
    CREATE (:File), (:Class), (:Function) nodes
    CREATE relationships (CONTAINS, IMPORTS)
  Output: Graph database populated

Step 8: Vector Storage
  For each code entity:
    VectorStore.add_code_chunk(code, metadata)
    Generate embedding using sentence-transformers
    Store in ChromaDB
  Output: Vector database populated

Step 9: Analysis
  PatternDetector.detect_patterns()
  CouplingAnalyzer.analyze_coupling()
  DependencyMapper.build_graph()
  Output: Analysis results

Step 10: Job Completion
  jobs[job_id] = {"status": "completed"}
  Frontend polls GET /status/{job_id}
  Frontend displays completion message

--------------------------------------------------------------------------------
4.2 PATTERN DETECTION FLOW
--------------------------------------------------------------------------------

Step 1: User Request
  User clicks "Patterns" tab
  Frontend: PatternDetection component

Step 2: API Request
  GET /patterns
  Backend: main.py -> PatternDetector

Step 3: Graph Query
  Query Neo4j for file structure
  MATCH (f:File) RETURN f.path, f.language

Step 4: Pattern Analysis
  Layered Architecture:
    - Check for presentation/business/data layers
    - Analyze dependency direction
    - Calculate confidence score
  
  MVC Pattern:
    - Check for controllers/models/views
    - Count files in each category
    - Calculate confidence score
  
  Hexagonal Architecture:
    - Check for ports/adapters/domain
    - Analyze call patterns
    - Calculate confidence score

Step 5: Response
  Return JSON:
  {
    "layered": {"detected": true, "confidence": 0.8, ...},
    "mvc": {"detected": true, "confidence": 0.9, ...},
    "hexagonal": {"detected": false, "confidence": 0.2, ...}
  }

Step 6: Frontend Display
  Render pattern cards with confidence scores
  Show detected patterns in green
  Show undetected patterns in gray

--------------------------------------------------------------------------------
4.3 IMPACT ANALYSIS FLOW
--------------------------------------------------------------------------------

Step 1: User Input
  User enters file path
  Frontend: ImpactAnalysis component

Step 2: API Request
  POST /impact {file_path: "src/auth.py"}
  Backend: main.py -> BlastRadiusAnalyzer

Step 3: Dependency Query
  Query Neo4j for dependencies:
  MATCH (target:File {path: $path})
  MATCH (affected:File)-[:IMPORTS*1..3]->(target)
  RETURN DISTINCT affected.path

Step 4: Risk Calculation
  blast_radius_size = len(affected_files)
  if size > 10: risk = "high"
  elif size > 5: risk = "medium"
  else: risk = "low"

Step 5: LLM Explanation
  Retrieve evidence from ChromaDB + Neo4j
  Send to LLM with prompt:
    "Explain the impact of changing {file_path}"
  LLM generates explanation with citations

Step 6: Response
  Return JSON:
  {
    "file": "src/auth.py",
    "blast_radius": ["login.py", "middleware.py", ...],
    "risk_level": "high",
    "impact_explanation": "Changing auth.py affects..."
  }

Step 7: Frontend Display
  Show affected files list
  Display risk level badge
  Render AI explanation

--------------------------------------------------------------------------------
4.4 HYBRID RETRIEVAL FLOW
--------------------------------------------------------------------------------

Step 1: User Query
  User asks: "How does authentication work?"
  Frontend: ArchitectureView component

Step 2: API Request
  GET /architecture?query="authentication"
  Backend: main.py -> RetrievalEngine

Step 3: Semantic Search
  ChromaDB.search("authentication", n_results=10)
  Returns files with high semantic similarity
  Output: [(file1, score1), (file2, score2), ...]

Step 4: Structural Context
  For top semantic results:
    Neo4j: Get dependencies and dependents
    MATCH (f:File {path: $file})-[:IMPORTS]->(dep)
    MATCH (f)<-[:IMPORTS]-(dependent)
  Output: Set of structurally related files

Step 5: Hybrid Merge
  For each result:
    if file in structural_context:
      boost_score += 0.5
  Sort by final score
  Return top 5 evidence chunks

Step 6: LLM Reasoning
  Construct prompt with evidence:
    "Based on these files: [evidence]
     Explain: How does authentication work?
     Rules: Cite files, no assumptions"
  
  Send to Groq API
  Receive explanation with citations

Step 7: Response
  Return JSON:
  {
    "explanation": "Authentication is handled by...",
    "evidence_files": ["auth.py", "middleware.py", ...],
    "macro": "System uses token-based auth...",
    "meso": "Auth module handles...",
    "micro": "auth.py contains..."
  }

Step 8: Frontend Display
  Render multi-level explanations
  Show evidence files as links
  Display citations

================================================================================
                        5. API ARCHITECTURE
================================================================================

--------------------------------------------------------------------------------
5.1 REST API ENDPOINTS
--------------------------------------------------------------------------------

Endpoint: POST /analyze
  Purpose: Start repository analysis
  Request: {"repo_url": "https://github.com/..."}
  Response: {"job_id": "...", "status": "processing"}
  Processing: Asynchronous background task

Endpoint: GET /status/{job_id}
  Purpose: Check analysis status
  Response: {"status": "processing|completed|failed"}

Endpoint: GET /patterns
  Purpose: Get detected architectural patterns
  Response: {
    "layered": {"detected": bool, "confidence": float, ...},
    "mvc": {...},
    "hexagonal": {...}
  }

Endpoint: GET /coupling
  Purpose: Get coupling metrics
  Response: {
    "high_coupling": [{file, fan_in, fan_out}, ...],
    "cycles": [[file1, file2, file1], ...],
    "metrics": {total_files, avg_coupling}
  }

Endpoint: POST /impact
  Purpose: Analyze change impact
  Request: {"file_path": "src/auth.py"}
  Response: {
    "file": "src/auth.py",
    "blast_radius": ["file1", "file2", ...],
    "risk_level": "high|medium|low",
    "impact_explanation": "..."
  }

Endpoint: GET /architecture
  Purpose: Get AI-generated architecture explanation
  Query Params: ?query="authentication"
  Response: {
    "explanation": "...",
    "evidence_files": [...],
    "macro": "...",
    "meso": "...",
    "micro": "..."
  }

Endpoint: GET /blast-radius/{file_path}
  Purpose: Get blast radius for specific file
  Response: {
    "file": "...",
    "affected_files": [...],
    "risk_level": "..."
  }

Endpoint: GET /dependencies/{file_path}
  Purpose: Get file dependencies
  Response: {
    "file": "...",
    "dependencies": [...],
    "dependents": [...]
  }

Endpoint: GET /graph/data
  Purpose: Get file dependency graph data
  Response: {
    "nodes": [{id, label, type}, ...],
    "links": [{source, target}, ...]
  }

Endpoint: GET /graph/functions
  Purpose: Get function call graph data
  Response: {
    "nodes": [{id, label, file}, ...],
    "links": [{source, target}, ...]
  }

--------------------------------------------------------------------------------
5.2 API DESIGN PATTERNS
--------------------------------------------------------------------------------

Pattern 1: Asynchronous Processing
  Long-running tasks (analysis) use background jobs
  Client polls status endpoint for completion
  Prevents timeout issues

Pattern 2: RESTful Design
  Resources: repositories, patterns, coupling, impact
  HTTP methods: GET (read), POST (create/analyze)
  Status codes: 200 (success), 404 (not found), 500 (error)

Pattern 3: JSON Responses
  All responses in JSON format
  Consistent structure: {data, status, message}

Pattern 4: CORS Enabled
  Allow cross-origin requests from frontend
  Headers: Access-Control-Allow-Origin: *

Pattern 5: Error Handling
  Try-catch blocks in all endpoints
  Return error details in response
  Log errors to server.log

================================================================================
                    6. DEPLOYMENT ARCHITECTURE
================================================================================

--------------------------------------------------------------------------------
6.1 DEVELOPMENT ENVIRONMENT
--------------------------------------------------------------------------------

Frontend:
  Command: npm start
  Port: 3000
  Hot Reload: Enabled
  Build: Development mode

Backend:
  Command: python main.py
  Port: 8000
  Reload: Manual restart
  Logging: Console + server.log

Neo4j:
  Command: docker run neo4j:5.14
  Ports: 7474 (HTTP), 7687 (Bolt)
  Auth: neo4j/password
  Data: Persistent volume

ChromaDB:
  Storage: backend/chroma_db/
  Mode: Embedded (no separate server)

--------------------------------------------------------------------------------
6.2 PRODUCTION ENVIRONMENT
--------------------------------------------------------------------------------

Frontend:
  Build: npm run build
  Output: build/ folder (static files)
  Serve: Nginx or Apache
  Port: 80/443 (HTTPS)

Backend:
  Server: Gunicorn + Uvicorn workers
  Command: gunicorn -w 4 -k uvicorn.workers.UvicornWorker main:app
  Port: 8000 (behind reverse proxy)
  Process Manager: systemd or supervisor

Neo4j:
  Deployment: Docker container or native install
  Backup: Automated daily dumps
  Monitoring: Neo4j metrics

ChromaDB:
  Storage: Persistent volume
  Backup: File system snapshots

Reverse Proxy:
  Nginx configuration:
    - Frontend: / -> static files
    - Backend: /api -> localhost:8000
    - Neo4j: /neo4j -> localhost:7474

--------------------------------------------------------------------------------
6.3 SCALING STRATEGY
--------------------------------------------------------------------------------

Horizontal Scaling:
  - Multiple backend instances behind load balancer
  - Shared Neo4j and ChromaDB instances
  - Session affinity not required (stateless API)

Vertical Scaling:
  - Increase CPU/RAM for analysis tasks
  - Neo4j memory tuning for large graphs
  - ChromaDB index optimization

Caching:
  - Redis for analysis results
  - CDN for frontend static files
  - Neo4j query result caching

================================================================================
                    7. PERFORMANCE CHARACTERISTICS
================================================================================

--------------------------------------------------------------------------------
7.1 RESPONSE TIMES
--------------------------------------------------------------------------------

Frontend:
  Initial Load: ~2 seconds
  Tab Switch: <100ms
  Graph Render: 500ms - 2s (depends on nodes)

Backend API:
  GET /patterns: 1-3 seconds
  GET /coupling: 1-2 seconds
  POST /impact: 500ms - 1 second
  GET /architecture: 2-5 seconds (LLM call)
  GET /graph/data: 100-500ms

Analysis:
  Small repo (<50 files): 30-60 seconds
  Medium repo (50-200 files): 1-3 minutes
  Large repo (200-1000 files): 3-10 minutes

Database:
  Neo4j query: 10-100ms
  ChromaDB search: 50-200ms
  Hybrid retrieval: 200-500ms

--------------------------------------------------------------------------------
7.2 RESOURCE USAGE
--------------------------------------------------------------------------------

Frontend:
  Memory: ~100MB (browser)
  CPU: Low (idle), Medium (graph rendering)

Backend:
  Memory: 500MB - 2GB (depends on repo size)
  CPU: High during analysis, Low during queries

Neo4j:
  Memory: 512MB - 4GB (configurable)
  Disk: 100MB - 10GB (depends on repo count)

ChromaDB:
  Memory: 200MB - 1GB
  Disk: 50MB - 5GB (depends on embeddings)

--------------------------------------------------------------------------------
7.3 SCALABILITY LIMITS
--------------------------------------------------------------------------------

Current Limits:
  - Max files per repo: ~1000 (tested)
  - Max concurrent analyses: 5 (background tasks)
  - Max graph nodes: 50,000 (Neo4j community)
  - Max embeddings: 1,000,000 (ChromaDB)

Bottlenecks:
  - AST parsing (CPU-bound)
  - Embedding generation (CPU-bound)
  - Graph traversal (memory-bound)
  - LLM API rate limits

Optimization Opportunities:
  - Parallel file parsing
  - Batch embedding generation
  - Graph query optimization
  - Result caching

================================================================================
                            END OF DOCUMENT
================================================================================
