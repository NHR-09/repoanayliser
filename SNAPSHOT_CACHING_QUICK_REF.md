# Snapshot Caching - Quick Reference

## What Changed?

### Before
```
Analyze repo â†’ Parse files â†’ Run analysis â†’ Call LLM â†’ Return results
(Every time, even for unchanged repos)
```

### After
```
Analyze repo â†’ Check commit hash â†’ Cache hit? â†’ Return cached results
                                  â†“ Cache miss
                                  Parse files â†’ Run analysis â†’ Call LLM â†’ Cache â†’ Return
```

## Key Benefits

âœ… **No redundant LLM calls** - Save API costs  
âœ… **Instant results** - 1-2 seconds vs 30-60 seconds  
âœ… **Automatic detection** - No manual configuration needed  
âœ… **Preserves history** - All snapshots kept for comparison  

## How to Use

### 1. First Analysis (Creates Cache)
```bash
POST /analyze
{
  "repo_url": "https://github.com/user/repo"
}

# Takes 30-60 seconds
# Creates snapshot with cached data
```

### 2. Subsequent Analysis (Uses Cache)
```bash
POST /analyze
{
  "repo_url": "https://github.com/user/repo"
}

# Takes 1-2 seconds
# Returns: {"cached": true}
```

### 3. After New Commit (Creates New Cache)
```bash
# Make changes and commit
git commit -m "new changes"

POST /analyze
{
  "repo_url": "https://github.com/user/repo"
}

# Takes 30-60 seconds
# Creates new snapshot for new commit
```

## Log Messages

### Cache Hit
```
âœ… No changes detected - using cached analysis
ğŸ“¦ Repository ID: abc123
ğŸ“¸ Cached Snapshot ID: xyz789
ğŸ’¾ Commit: a1b2c3d4
```

### Cache Miss
```
ğŸš€ Starting repository analysis
ğŸ“¦ Repository ID: abc123
ğŸ“¸ New Snapshot ID: new123
ğŸ“ Parsing 50 files...
```

## API Endpoints

### Check Snapshots
```bash
GET /repository/{repo_id}/snapshots
```

### Compare Snapshots
```bash
GET /repository/{repo_id}/compare-snapshots/{s1}/{s2}
```

### Delete Snapshot
```bash
DELETE /repository/{repo_id}/snapshot/{snapshot_id}
```

## When Cache is Used

âœ… Same repository URL  
âœ… Same Git commit hash  
âœ… Snapshot has cached data  

## When Cache is NOT Used

âŒ Different commit hash  
âŒ New repository  
âŒ Snapshot deleted  
âŒ First analysis  

## Cached Data

- Pattern detection results
- Coupling analysis
- Architecture explanations (macro/meso/micro)
- Dependency metrics
- File counts

## Not Cached

- Raw file contents
- AST parsing results
- Vector embeddings (regenerated if needed)

## Cost Savings Example

### 10 Analyses of Same Repo

**Without Caching:**
- Time: 10 Ã— 45s = 450 seconds (7.5 minutes)
- LLM calls: 10 Ã— 4 = 40 calls
- Cost: 10 Ã— $0.10 = $1.00

**With Caching:**
- Time: 45s + (9 Ã— 2s) = 63 seconds (1 minute)
- LLM calls: 4 calls
- Cost: $0.10

**Savings: 86% time, 90% cost**

## Troubleshooting

### Cache Not Working?
1. Check commit hash: `git rev-parse HEAD`
2. Verify snapshot exists: `GET /repository/{repo_id}/snapshots`
3. Check logs for "âœ… No changes detected"

### Force Fresh Analysis?
1. Make a new commit: `git commit --allow-empty -m "force"`
2. Or delete snapshot: `DELETE /repository/{repo_id}/snapshot/{id}`

### Multiple Snapshots?
- Normal behavior - one per commit
- Use compare endpoint to see differences
- Delete old snapshots if needed

## Implementation Files

- `backend/src/analysis_engine.py` - Main caching logic
- `backend/src/graph/version_tracker.py` - Commit tracking
- `backend/main.py` - API endpoints
- `SNAPSHOT_CACHING.md` - Full documentation

---

**TL;DR**: System now caches analysis results per commit. Same commit = instant cached results. New commit = fresh analysis + new cache.
